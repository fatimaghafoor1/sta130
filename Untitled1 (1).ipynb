{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566cdeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x          y unique_squirrel_id hectare shift      date  \\\n",
      "0 -73.956134  40.794082     37F-PM-1014-03     37F    PM  10142018   \n",
      "1 -73.968857  40.783783     21B-AM-1019-04     21B    AM  10192018   \n",
      "2 -73.974281  40.775534     11B-PM-1014-08     11B    PM  10142018   \n",
      "3 -73.959641  40.790313     32E-PM-1017-14     32E    PM  10172018   \n",
      "4 -73.970268  40.776213     13E-AM-1017-05     13E    AM  10172018   \n",
      "\n",
      "   hectare_squirrel_number    age primary_fur_color highlight_fur_color  ...  \\\n",
      "0                        3    NaN               NaN                 NaN  ...   \n",
      "1                        4    NaN               NaN                 NaN  ...   \n",
      "2                        8    NaN              Gray                 NaN  ...   \n",
      "3                       14  Adult              Gray                 NaN  ...   \n",
      "4                        5  Adult              Gray            Cinnamon  ...   \n",
      "\n",
      "    kuks  quaas  moans tail_flags tail_twitches  approaches  indifferent  \\\n",
      "0  False  False  False      False         False       False        False   \n",
      "1  False  False  False      False         False       False        False   \n",
      "2  False  False  False      False         False       False        False   \n",
      "3  False  False  False      False         False       False        False   \n",
      "4  False  False  False      False         False       False        False   \n",
      "\n",
      "   runs_from  other_interactions                             geocoded_column  \n",
      "0      False                 NaN  POINT (-73.9561344937861 40.7940823884086)  \n",
      "1      False                 NaN  POINT (-73.9688574691102 40.7837825208444)  \n",
      "2      False                 NaN  POINT (-73.97428114848522 40.775533619083)  \n",
      "3       True                 NaN  POINT (-73.9596413903948 40.7903128889029)  \n",
      "4      False                 NaN  POINT (-73.9702676472613 40.7762126854894)  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://data.cityofnewyork.us/resource/vfnx-vebw.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34ba90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1000, Columns: 31\n"
     ]
    }
   ],
   "source": [
    "rows, columns = data.shape\n",
    "print(f\"Rows: {rows}, Columns: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1750e",
   "metadata": {},
   "source": [
    "\"Observations\" and \"Variables\" are like saying rows and coloumns but in terms of a dataset. The observations represent the rows so each observation would be the record of one record of data. In regards to the dataset I have used, each observation would be the record of data for each squirrel. In even simpler terms, all the details of a specific squirrel. The variables represent the colomns. So each individual attribute/detail of the squirrels is each variable. For exampple unique_squirrel_id is a variable and it is the indvidual coloumn which is filled with a specific feature of the squirrel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e599ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for unique_squirrel_id:\n",
      " unique_squirrel_id\n",
      "37F-PM-1014-03    1\n",
      "34E-PM-1006-01    1\n",
      "22F-AM-1007-03    1\n",
      "5I-AM-1010-01     1\n",
      "12C-AM-1013-01    1\n",
      "                 ..\n",
      "1H-AM-1012-01     1\n",
      "8H-PM-1014-05     1\n",
      "30E-AM-1008-01    1\n",
      "16A-PM-1019-04    1\n",
      "2A-AM-1010-08     1\n",
      "Name: count, Length: 1000, dtype: int64 \n",
      "\n",
      "Value counts for hectare:\n",
      " hectare\n",
      "36I    14\n",
      "14E    14\n",
      "13E    11\n",
      "07H    10\n",
      "32E    10\n",
      "       ..\n",
      "18F     1\n",
      "19H     1\n",
      "42B     1\n",
      "28A     1\n",
      "29I     1\n",
      "Name: count, Length: 306, dtype: int64 \n",
      "\n",
      "Value counts for shift:\n",
      " shift\n",
      "PM    555\n",
      "AM    445\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for age:\n",
      " age\n",
      "Adult       840\n",
      "Juvenile    106\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for primary_fur_color:\n",
      " primary_fur_color\n",
      "Gray        825\n",
      "Cinnamon    126\n",
      "Black        34\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for highlight_fur_color:\n",
      " highlight_fur_color\n",
      "Cinnamon                  270\n",
      "White                     179\n",
      "Cinnamon, White            82\n",
      "Gray                       52\n",
      "Gray, White                22\n",
      "Black                      13\n",
      "Black, Cinnamon, White     11\n",
      "Black, Cinnamon             3\n",
      "Black, White                2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for combination_of_primary_and:\n",
      " combination_of_primary_and\n",
      "Gray+                          302\n",
      "Gray+Cinnamon                  267\n",
      "Gray+White                     148\n",
      "Gray+Cinnamon, White            82\n",
      "Cinnamon+Gray                   50\n",
      "Cinnamon+White                  30\n",
      "Black+                          28\n",
      "Cinnamon+Gray, White            22\n",
      "Cinnamon+                       21\n",
      "+                               15\n",
      "Gray+Black, Cinnamon, White     11\n",
      "Gray+Black                      10\n",
      "Black+Cinnamon                   3\n",
      "Cinnamon+Black                   3\n",
      "Gray+Black, Cinnamon             3\n",
      "Gray+Black, White                2\n",
      "Black+Gray                       2\n",
      "Black+White                      1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for color_notes:\n",
      " color_notes\n",
      "Nothing selected as Primary. Gray selected as Highlights. Made executive adjustments.                                3\n",
      "Cinnamon stripe on back                                                                                              2\n",
      "Gray & Cinnamon selected as Primary. Nothing selected as Highlights. Made executive adjustments.                     2\n",
      "White legs, front & back                                                                                             1\n",
      "Gray, Cinnamon & White selected as Primary. White selected as Highlights. Made executive adjustments.                1\n",
      "gray tail                                                                                                            1\n",
      "Could be same squirrel as #1?                                                                                        1\n",
      "young adult                                                                                                          1\n",
      "Partial missing tail                                                                                                 1\n",
      "White tail                                                                                                           1\n",
      "large white highlight                                                                                                1\n",
      "Black stripe along sides                                                                                             1\n",
      "3/4 length tail, hair loss                                                                                           1\n",
      "Cinnamon along back & tail                                                                                           1\n",
      "Side stripes                                                                                                         1\n",
      "white haunches                                                                                                       1\n",
      "Gray & Cinnamon selected as Primary. Black selected as Highlights. Made executive adjustments.                       1\n",
      "Very far, so appx                                                                                                    1\n",
      "White belly                                                                                                          1\n",
      "injured                                                                                                              1\n",
      "patches of white on haunches                                                                                         1\n",
      "(very brown)                                                                                                         1\n",
      "white belly                                                                                                          1\n",
      "Gray, Black, & Cinnamon selected as Primary. Cinnamon & White selected as Highlights. Made executive adjustments.    1\n",
      "Listed as primary white with cinnamon highlights, I changed to Gray/cinnamon - JO                                    1\n",
      "just outside hectare                                                                                                 1\n",
      "white neck and belly                                                                                                 1\n",
      "Gray & White selected as Primary. Black & Cinnamon selected as Highlights. Made executive adjustments.               1\n",
      "Gray & Cinnamon selected as Primary. Cinnamon selected as Highlights. Made executive adjustments.                    1\n",
      "Cinnamon belly                                                                                                       1\n",
      "cinnamon tail                                                                                                        1\n",
      "Too far & cloudy to tell                                                                                             1\n",
      "Cinnamon head & stripe                                                                                               1\n",
      "White selected as Primary. Cinnamon selected as Highlights. Made executive adjustments.                              1\n",
      "white patch                                                                                                          1\n",
      "No Tail!                                                                                                             1\n",
      "Off-white, decorator's white?                                                                                        1\n",
      "Darker than others                                                                                                   1\n",
      "Gray, Cinnamon & White selected as Primary. Gray & White selected as Highlights. Made executive adjustments.         1\n",
      "too far to note 30'                                                                                                  1\n",
      "\"Brown\" written in as Primary                                                                                        1\n",
      "Gray & Cinnamon selected as Primary. White selected as Highlights. Made executive adjustments.                       1\n",
      "White patches. Almost looks like fox squirrel                                                                        1\n",
      "Drawing included.                                                                                                    1\n",
      "Cinnamon on its head                                                                                                 1\n",
      "notch on tail                                                                                                        1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for location:\n",
      " location\n",
      "Ground Plane    713\n",
      "Above Ground    267\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for above_ground_sighter:\n",
      " above_ground_sighter\n",
      "FALSE    713\n",
      "10        37\n",
      "15        29\n",
      "3         20\n",
      "20        19\n",
      "5         18\n",
      "2         17\n",
      "30        16\n",
      "25        12\n",
      "4         11\n",
      "6          8\n",
      "8          7\n",
      "1          7\n",
      "7          6\n",
      "40         6\n",
      "50         6\n",
      "12         5\n",
      "13         5\n",
      "18         2\n",
      "9          2\n",
      "28         2\n",
      "35         2\n",
      "100        1\n",
      "80         1\n",
      "65         1\n",
      "24         1\n",
      "17         1\n",
      "55         1\n",
      "60         1\n",
      "180        1\n",
      "70         1\n",
      "45         1\n",
      "0          1\n",
      "43         1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Value counts for specific_location:\n",
      " specific_location\n",
      "tree                                                          18\n",
      "in tree                                                        7\n",
      "on fence                                                       4\n",
      "under bushes                                                   3\n",
      "under a tree                                                   3\n",
      "                                                              ..\n",
      "on tree trunk                                                  1\n",
      "Bridle Path lawn                                               1\n",
      "gingko tree by traffic light in front of Strawberry Fields     1\n",
      "treed area                                                     1\n",
      "in tree!                                                       1\n",
      "Name: count, Length: 126, dtype: int64 \n",
      "\n",
      "Value counts for other_activities:\n",
      " other_activities\n",
      "walking                                                         7\n",
      "burying                                                         6\n",
      "digging                                                         6\n",
      "sitting                                                         5\n",
      "jumping                                                         4\n",
      "                                                               ..\n",
      "together w/ #7                                                  1\n",
      "sitting in tree                                                 1\n",
      "posing                                                          1\n",
      "sitting still                                                   1\n",
      "stood still & watched me then jumped on a fence and ran away    1\n",
      "Name: count, Length: 119, dtype: int64 \n",
      "\n",
      "Value counts for other_interactions:\n",
      " other_interactions\n",
      "stared                                         3\n",
      "me                                             2\n",
      "dog chased                                     2\n",
      "avoided people                                 2\n",
      "runs from (me)                                 2\n",
      "                                              ..\n",
      "ran up tree when approached                    1\n",
      "indifferent (moving very fast)                 1\n",
      "too busy eating in his tree                    1\n",
      "ran away when a human approached with a dog    1\n",
      "asleep                                         1\n",
      "Name: count, Length: 82, dtype: int64 \n",
      "\n",
      "Value counts for geocoded_column:\n",
      " geocoded_column\n",
      "POINT (-73.9561344937861 40.7940823884086)    1\n",
      "POINT (-73.958417813526 40.7927301214476)     1\n",
      "POINT (-73.9638298997554 40.7825966332367)    1\n",
      "POINT (-73.9700759073973 40.7680560871695)    1\n",
      "POINT (-73.9721854790038 40.7761086352438)    1\n",
      "                                             ..\n",
      "POINT (-73.9744960829844 40.7652585501959)    1\n",
      "POINT (-73.9703161745884 40.7702610461336)    1\n",
      "POINT (-73.9605966636226 40.7889849108637)    1\n",
      "POINT (-73.9730224561601 40.7796833353894)    1\n",
      "POINT (-73.9805137046778 40.769275143797)     1\n",
      "Name: count, Length: 1000, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_summary = data.describe()\n",
    "categorical_summary = data.describe(include=['object'])\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    print(f\"Value counts for {col}:\\n\", data[col].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e78daf",
   "metadata": {},
   "source": [
    "4. a. To understand the discrepancies between size of the dataset given by df.shape and df.describe() with respect to the number of columns it analyzes, I'll first explain what my understanding of both of these individually output. Firstly, df.shape is a method that outputs a tuple which consists of the number of rows and number of columns in the entire dataset. df.describe() on the otherhand only looks over the columns that contain numerical values and unless otherwise stated (as a clear condition to include all), df.describe() would only output the certain columns that only contain numerical values. Thus the discrepancy between the size of the dataset occurs as df.shape will give out the entire dataset while df.describe() will only report numerical columns. So if there are any non-numerical columns in the dataset they won't be returned by df.describe() and their would be a size discrepancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd38a7",
   "metadata": {},
   "source": [
    "b. The discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to the values it reports in the \"count\" column occur as df.shape will return the same number of rows that are present in the dataset as tuple, however df.describe() only returns the row count of columns with numerical values that are not empty. Empty rows will not be counted and this is what causes the size discrepancy in terms of the values returned in the count column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146e55e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1378284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 x            y          date  hectare_squirrel_number\n",
      "count  1000.000000  1000.000000  1.000000e+03              1000.000000\n",
      "mean    -73.967020    40.781087  1.011853e+07                 4.170000\n",
      "std       0.007698     0.010139  4.267014e+04                 3.151989\n",
      "min     -73.980961    40.765008  1.006202e+07                 1.000000\n",
      "25%     -73.972957    40.772389  1.007202e+07                 2.000000\n",
      "50%     -73.968374    40.778225  1.012202e+07                 3.000000\n",
      "75%     -73.959765    40.791285  1.014202e+07                 6.000000\n",
      "max     -73.949722    40.800046  1.020202e+07                23.000000\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca79bdc",
   "metadata": {},
   "source": [
    "5. Attributes are usually retrieved without using the () however a method will always require a () after it. Attributes are a specific feature of an object in the dataset. Methods are like the functions that can be used for a specific objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c720d3",
   "metadata": {},
   "source": [
    "The link to my ChatGPT interaction: https://chatgpt.com/share/69973eaa-ae78-4377-a9fb-16ba244f7654"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0908f",
   "metadata": {},
   "source": [
    "Here is the summary of my interaction with ChatGPT: Here's a summary of our session:\n",
    "\n",
    "Dataset Analysis:\n",
    "\n",
    "You inquired about checking the number of rows and columns in a dataset from a given CSV file.\n",
    "We discussed methods to get the number of rows and columns using Python and pandas, as well as using spreadsheet applications.\n",
    "Observations and Variables:\n",
    "\n",
    "We clarified that in a dataset, rows represent observations, and columns represent variables.\n",
    "Summarizing Data:\n",
    "\n",
    "We covered how to provide summaries of columns using df.describe() for numerical columns and df[col].value_counts() for categorical columns.\n",
    "Discrepancies:\n",
    "\n",
    "We explored discrepancies between the size of the dataset reported by df.shape and the summaries provided by df.describe(), particularly regarding the number of columns and the count of non-null values.\n",
    "Attributes vs. Methods:\n",
    "\n",
    "We explained the difference between attributes (e.g., df.shape) and methods (e.g., df.describe()) in Python, including their syntax and purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b38a6c",
   "metadata": {},
   "source": [
    "The definition of the following stasticial summaries :\n",
    "Count : The number of data values present in the dataset for a specific variable. \n",
    "Mean: The mean is the average of of a group of values and is calculated by adding the values and then dividing by the number of values. \n",
    "Standard deviation: The SD describes the spread of a group of values around the mean. It basically shows how distributed the values are on either side of the mean on the normal distribution graph. If the standard deviation is high that means the values are very spread apart from the mean and we can deduce the range was large. If the standard deviation is low that means the values are not spread apart from the mean so the range would be the little. \n",
    "Minimum: The smallest value in the set of values.\n",
    "25% Percentile: Also called the Q1. It is the value that marks the 1/4 of the total data. Represents the cut off value of the bottom 25% of the data.\n",
    "50% Percentile: Also called the median which represents the value in the middle of the dataset. The median divides the bottom 50% of the data and the top 50%.\n",
    "75% Percentile: Marks the 75% mark or 3/4 of the data. Everything below the 75% percentile represents the bottom 75% of the datavelues.\n",
    "Maximum: The greatest value in the set of all the values in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b602a1",
   "metadata": {},
   "source": [
    "7. part 1: case when f.dropna() might be peferred over using del df['col']: \n",
    "   When a student survey is sent out and the students are required to answer some questions related to how they are feeling about a certain course. Some students might not answer every question and leave it blank which would mean our dataset will have some missing values. Using f.dropna() would be more efficient and would lose less data from the dataset as it would only the remove the specific row in which a student hasn't answered a question. If we used del df['col'] then the entire column which had the missing value would be removed. This would remove all the data from the other students too related to the specific question(column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd82e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'Name': ['Grace', 'Louis', 'Anna', 'Hayden', 'Frank'],\n",
    "    'Classes taken': [1, 4, None, 4, 6],  \n",
    "    'Hours spent': [None, 9, 24, 8, 32],  \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2ac31",
   "metadata": {},
   "source": [
    "part 2: Provide an example of \"the opposite use case\" in which using del df['col']:  might be preferred over using df.dropna()A pre-party form which asks people if they have any allergies to any specific food such as dairy, gluten, eggs etc. If they are not allergic comment \"N/A\" and if they are then leave the question blank. Alot of missing values in a specific column would indicate alot of people are allergic to a certain food. In this case we would prefer using del df['col'] so that the entire column of responses to that specific food is removed so the party hosts are aware to not use that food in any of the party dishes. This way we also don't lose the data for the entire row so we know what that guest ISNT'T allergic too so the hosts have an easy time planning the food dishes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c1744",
   "metadata": {},
   "source": [
    "part 3: Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "del df['col'] removes columns and df.dropna() removes entire rows. To put it into perspective of importance, lets say the columns in a dataset are 'Name', 'Number', 'City', 'Personal Email', 'Work Email']. There is a likely chance that alot of people may not have a work email or use their personal email as their work email and so leave the work email column blank. Thus, we can infer that the work email column may have many missng values. If we use df.dropna(), then the entire row that contains a missing value gets deleted. This way we are loosing other valuable data as well like the responses to the 'Name', 'Number', 'City', 'Personal Email' columns too and this could potentially remove vital information from a dataset. On the otherhand if we use del df['col'] then we can infer that the work email column would be removed as it has many missing values. This would be much more efficient, faster and cause less data loss. Furthermore, as df.dropna() removes data row wise while del df['col'] removes data column wise, del df['col'] would probably take alot less time to filter the dataset. Especially if its a dataset with alot of rows as unwanted columns will be removed first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5746b10",
   "metadata": {},
   "source": [
    "part 4: The dataset I am using is one I made up and it is very small but for explanation purposes should suffice. First I'll report the before which would be: \n",
    "   Name of Customer  Rating  Phone number\n",
    "0              Ella       1          None\n",
    "1             Hanna       4       889912\n",
    "2              None       2       234123\n",
    "3               Zoe       2          None\n",
    "4               Lea       5          None\n",
    "The approach I would use it to first use df.dropna() and then use del df['col']. The reason I would use df.dropna() first would be to remove rows which has a missing value in the Name of Customer column as this dataset is used as a review of customer service and for the information to be useful and considered 'serious' the presence of a customer name is important. Otherwise, it could be implied that the survey was filled unseriously. If the name of customer column is empty for a specific row is empty then the rest of the data filled out doesn't remain as important for us and removing the entire row wouldn't cause dataloss of important info. After we have applied df.dropna() we can then apply del df['col'] because now we can examine which columns have a lot missing values and then we can choose to leave that column out because if a lot of the customers are not answering a specific question we can leave that column out and still have sufficient/relevant information left. \n",
    "My after of this dataset after using df.dropna() first and then del df['col'] would be:\n",
    " Name of Customer  Rating  Phone number\n",
    "1             Hanna       4       889912\n",
    "\n",
    "Now my dataset doesn't have any missing values left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b3649",
   "metadata": {},
   "source": [
    "8. 1. For my example I am going to use \"embarked\" for col1 and \"pclass\" for col2 grouping. What means in very simple words is that we group col1 and provide the statistical summaries of the col2 values. I'll break the function down and explain step by step. The whole function is df.groupby(\"col1\")[\"col2\"].describe() but lets start with just df.groupby(\"col1\"). This part groups the titanic dataframe using values from col1 which in my chosen case is embarked. In the next part of the function [\"col2\"] we are basically choosing the second column who's values we want to observe. In this case I have chosen the pclass column. Now the last part of the function .describe() is what actually provides the statistical summaries of the values in our selected col2 (pclass) in groups from col1 (embarked). So the code would look something like this data = {grouped_pclass = df.groupby(\"embarked\")[\"pclass\"].describe() and then print(grouped_pclass). The output would have a first column called emabarked and then all other columns would be statistical summaries like mean, standard deviation, median, 25% percentile etc of each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad9d62",
   "metadata": {},
   "source": [
    "8. 2. Both df.describe() and df.groupby(\"col1\")[\"col2\"].describe() provide us with statistical summaries but we may get different answers when we use the count statistical summary with both of these and that is due to how each function interprates the data. I'll explain the different ways both of these understand that data in terms of count. Firstly, df.describe() ignores all the missing values and provides the count values for the non missing values. For example, there are 900 rows and there are 850 non missing values then df.describe() would give us 850 as the count value. When we use df.groupby(\"col1\")[\"col2\"].describe(), our count value depends on col1 as well hence we have a different interpretation. Since the values are first grouped using unique values from col1, the count function basically gives us the non missing values in col2 within every gorup of col1. So the count value we get would be how many values were present in col2 for the values of the group from col1. Thus the count value would reflect how data is distributed in subsections of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea9d1d",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/66e3b6eb-b8c4-800b-8e6d-6f6543a5e9f1\n",
    "\n",
    "Summary: Certainly! Here's a summary of our interaction:\n",
    "\n",
    "Initial Query: You asked for an explanation of the code df.groupby(\"col1\")[\"col2\"].describe() and what it does.\n",
    "\n",
    "Explanation Provided:\n",
    "\n",
    "df.groupby(\"col1\"): Groups the DataFrame by unique values in column \"col1\".\n",
    "[\"col2\"]: Selects column \"col2\" from each group.\n",
    ".describe(): Computes summary statistics (count, mean, std, min, percentiles, max) for column \"col2\" within each group.\n",
    "Example Demonstration:\n",
    "\n",
    "Provided a code example using sample data and demonstrated how grouping by \"pclass\" and describing \"fare\" yields descriptive statistics for each passenger class.\n",
    "Follow-up Question: You inquired about why count in df.groupby(\"col1\")[\"col2\"].describe() captures something fundamentally different from other statistics such as mean, std, etc.\n",
    "\n",
    "Detailed Explanation:\n",
    "\n",
    "count: Represents the number of non-null entries in the column for each group. It helps assess data completeness and affects the calculation of other statistics.\n",
    "Other Statistics: Include mean, std, min, percentiles, and max, which provide insights into the distribution and spread of the values in the column.\n",
    "Illustrative Example:\n",
    "\n",
    "Provided an example with missing values to show how count reflects the number of valid data points and how it influences the calculation of other descriptive statistics.\n",
    "This summary captures the main points of our discussion and how each aspect of the describe() function's output contributes to understanding your data. If you need further clarification or additional details, feel free to ask!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926fb48",
   "metadata": {},
   "source": [
    "A. The name error was more efficiently solved using the chatbox rather than a google search as I was able to copy the exact error into the chatbox and ask it whats wrong. I was given an accurate answer within seconds which would fix my code error very fast. Chatbox correctly identified the missing part was the import statments. However when I ran a google search the top result suggested that I was mising double quotation marks as the reason for the error which is clearly not as accurate as the chatbox answer and hence for this error the chatbox was more useful and quick. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9b2fa",
   "metadata": {},
   "source": [
    "B. For the FileNotFoundError: [Errno 2] No such file or directory error I found that google and chatbox weren't very different in their accuracy and efficiency. I got a longer answer from the chatbox so it took a while to load while the google search was abit faster. However, both gave me right answers of their being something wrong with the file path which would help me infer I have either entered the wrong URL or spelled something wrong. Howver if I wanted a more precise answer and a detailed explanation of why I was getting the error then the chatbox would be the better option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cfe2b1",
   "metadata": {},
   "source": [
    "C. For the NameError: name 'DF' is not defined error, I found the chatbox answer alot more quick and effective. It correctly identified a case sensitivity problem. However with google, there was first alot of different links to open and then making sure that the webpage is reffering to the same error that I am reffering too. Although Google also got to the write answer of something being wrong with the \"df\" chatbox was alot more fast and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b7175",
   "metadata": {},
   "source": [
    "D. The chatbox was able to guess the reason for the syntax error as the first answer it gave me (Missing paranthasis) Thus Chatbox was more accurate and fast as compared to the google search which was giving very unspecific answers which would take me a while to identify what was actually wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9b24d",
   "metadata": {},
   "source": [
    "E. The attribute error's cause was correctly identified by both chatbox and google and both were very efficient. They both got to the correct reason however the chatbox \n",
    "is able to provide you with exmaples and visual representations of how to fix the error while using google means you are only given word answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355edaf",
   "metadata": {},
   "source": [
    "F. I got a key error and both chatbox and google gave me the accurate answer which was I could be trying to access a non existing dictionary. Thus both were equally good at providing answer however this time google had actual student examples as a search result too so I would say google provided a more realistic idea of the error and how people would fix theirs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2ad176",
   "metadata": {},
   "source": [
    "G. The reason for the name error was quicker identified by chatbox which also ilustrated examples of many ways to try to fix the name error. Google was abit more unspecific and would require visiting alot of webpages to find the right one which would give enough hints on how to fix the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259debca",
   "metadata": {},
   "source": [
    "Here is a link of my chatgpt interaction and a sumamry : https://chatgpt.com/share/66e3b624-1f88-800b-921c-3bfa2bf9b68d\n",
    "Certainly! Hereâ€™s a summary of our interaction:\n",
    "\n",
    "Initial Issues with df.groupby and df.describe():\n",
    "\n",
    "You inquired about the functionality of df.groupby(\"col1\")[\"col2\"].describe() and how it differs from df.describe().\n",
    "I explained that df.groupby(\"col1\")[\"col2\"].describe() provides summary statistics for col2, grouped by unique values of col1, whereas df.describe() gives summary statistics for all numeric columns in the DataFrame.\n",
    "Handling Errors:\n",
    "\n",
    "You encountered a NameError related to using pd and received guidance to ensure proper imports and correct naming.\n",
    "You faced a FileNotFoundError when trying to load a dataset from a URL, which was resolved by checking the URL and ensuring internet access.\n",
    "You received a SyntaxError and I provided common causes and fixes for syntax issues.\n",
    "You encountered a KeyError and learned about common causes and solutions, including using the get() method and checking key existence.\n",
    "You also faced an AttributeError, where I explained how to verify attribute existence and correct typographical errors.\n",
    "Fixing Key and Attribute Errors:\n",
    "\n",
    "I detailed how to fix a KeyError by checking if keys exist before accessing them and using the get() method or handling exceptions.\n",
    "For AttributeError, I provided ways to ensure that methods or attributes exist on the object and are correctly named.\n",
    "Fixing NameError with df.groupby:\n",
    "\n",
    "We discussed troubleshooting NameError related to using df.groupby by ensuring proper definition and spelling of DataFrame and column names, checking for typographical errors, and verifying the object type.\n",
    "Feel free to ask if you need further clarification or help with any other issues!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666995f",
   "metadata": {},
   "source": [
    "9. Yes, I made sure I kept my conversation with ChatGPT natural and asked any extra questions I needed to ask for my own understanding in the session that I have reported in the homework too. As well as ChatGPT, I also took the help of my TA during Wednesdays office hours regarding submitting using Github. Also making sure before I write something I get from ChatGPT, I understand is clearly and so what I'm writing makes sense to me helped me understand all the new methods I have encountered in this homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
